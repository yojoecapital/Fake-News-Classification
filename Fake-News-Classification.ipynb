{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVpnFsovlhc0"
   },
   "source": [
    "# Project 2 Code\n",
    "## Steps\n",
    "1. Preprocess titles by removing stopwords and stemming\n",
    "  - stopwords are common english tokens like \"the\" and \"a\"\n",
    "  - stemming is reducing words to their roots\n",
    "2. Vectorize the titles by using TF-IDF on each pairing\n",
    "  - define some `vectorSize` and either pad the vectors or limit them to it\n",
    "3. Train a Siamese neural network to back a similarity scoring\n",
    "4. Use some threshold to determine if the pairs are `agree`, `disagree`, or `unrelated`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvmGt6k9lfRS",
    "outputId": "967e93e2-ec7c-48d0-d42d-ddd263e7a5e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yousef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yousef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# preprocess a single title\n",
    "def preprocess_title(title):\n",
    "    # convert to lowercase and remove punctuation\n",
    "    title = title.lower()\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    title = title.translate(translator)\n",
    "    # tokenize\n",
    "    words = nltk.word_tokenize(title)\n",
    "    # remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    # stem the remaining words\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # join the stemmed words back into a single string\n",
    "    stemmed_title = ' '.join(words)\n",
    "    return stemmed_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure a vector is at most max_len by either trimming it or adding empty\n",
    "def ensure_length(lst, max_len, empty):\n",
    "    if len(lst) > max_len:\n",
    "        lst = lst[:max_len]\n",
    "    elif len(lst) < max_len:\n",
    "        lst += [empty] * (max_len - len(lst))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPPJvaOtoOJs",
    "outputId": "e69ea469-c845-4b61-b6d0-d877f000d0f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articl</th>\n",
       "      <th>fake</th>\n",
       "      <th>im</th>\n",
       "      <th>news</th>\n",
       "      <th>real</th>\n",
       "      <th>realli</th>\n",
       "      <th>sure</th>\n",
       "      <th>titl</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.576152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     articl      fake        im      news      real    realli      sure  \\\n",
       "0  0.576152  0.576152  0.000000  0.409937  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.446656  0.317800  0.446656  0.446656  0.446656   \n",
       "\n",
       "       titl  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "0  0.409937    0    0    0    0    0    0    0    0  \n",
       "1  0.317800    0    0    0    0    0    0    0    0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "titles = [preprocess_title(title) for title in ['I am a title of a faked news article...', 'I\\'m not really sure if this news title is real?']]\n",
    "# create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "# compute the TF-IDF weights for the titles\n",
    "max_len = 16\n",
    "title_vectors = list(map(lambda v: ensure_length(v, max_len, 0), vectorizer.fit_transform(titles).todense().tolist()))\n",
    "token_labels = ensure_length(vectorizer.get_feature_names_out().tolist(), max_len, \"...\")\n",
    "# ensure legnth 10\n",
    "\n",
    "pd.DataFrame(title_vectors, columns=token_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KCeWPE89EHI",
    "outputId": "1a8bbd7c-1b7c-4847-c3db-6db6f3ee1759"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\JHP10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.486, 'neu': 0.264, 'pos': 0.251, 'compound': -0.5519}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really lame. I hate it!\") # returns an array, [neg score, neutral score, pos score,]\n",
    "\n",
    "# cosine first\n",
    "# euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CMkiYEEmvbT"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "YDwUOgx89e8q",
    "outputId": "badbd794-ec92-4f72-a8f2-477ea9e6684c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191474</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25300</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123757</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP overtakes Hong Kong? Bureau of ...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141761</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outpaces Hong Kong? Defending R...</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  tid1  tid2                                          title1_en  \\\n",
       "0  195611     0     1  There are two new old-age insurance benefits f...   \n",
       "1  191474     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   25300     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3  123757     2     8  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4  141761     2    11  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "\n",
       "                                           title2_en      label  \n",
       "0  Police disprove \"bird's nest congress each per...  unrelated  \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated  \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated  \n",
       "3  Shenzhen's GDP overtakes Hong Kong? Bureau of ...  unrelated  \n",
       "4  Shenzhen's GDP outpaces Hong Kong? Defending R...  unrelated  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VIhH6El6nJYM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2060\\352005077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtitle2_sentiment_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtitle1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title1_en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title2_en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mtitle1_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# score range is [-1,1], where 1 is good and -1 is bad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mtitle1_sentiment_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle1_sent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate sentiment scores for each article title\n",
    "# expect about a 2 minute runtime\n",
    "title1_sentiment_data = []\n",
    "title2_sentiment_data = []\n",
    "\n",
    "for title1, title2 in zip(train_df['title1_en'], train_df['title2_en']):\n",
    "    title1_sent = sia.polarity_scores(title1)['compound'] # score range is [-1,1], where 1 is good and -1 is bad\n",
    "    title1_sentiment_data.append(title1_sent)\n",
    "\n",
    "    title2_sent = sia.polarity_scores(title2)['compound']\n",
    "    title2_sentiment_data.append(title2_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xdzgVvkOpIuW",
    "outputId": "10135a02-991d-4e49-c407-a10e15ffe6c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "      <th>title1_sentiment</th>\n",
       "      <th>title2_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191474</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25300</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123757</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP overtakes Hong Kong? Bureau of ...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141761</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outpaces Hong Kong? Defending R...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  tid1  tid2                                          title1_en  \\\n",
       "0  195611     0     1  There are two new old-age insurance benefits f...   \n",
       "1  191474     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   25300     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3  123757     2     8  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4  141761     2    11  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "\n",
       "                                           title2_en      label  \\\n",
       "0  Police disprove \"bird's nest congress each per...  unrelated   \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated   \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated   \n",
       "3  Shenzhen's GDP overtakes Hong Kong? Bureau of ...  unrelated   \n",
       "4  Shenzhen's GDP outpaces Hong Kong? Defending R...  unrelated   \n",
       "\n",
       "   title1_sentiment  title2_sentiment  \n",
       "0            0.3818               0.0  \n",
       "1            0.0000               0.0  \n",
       "2            0.0000               0.0  \n",
       "3            0.0000               0.0  \n",
       "4            0.0000               0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['title1_sentiment'] = title1_sentiment_data\n",
    "train_df['title2_sentiment'] = title2_sentiment_data\n",
    "train_df.to_csv('train-transformed.csv', index=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OaVN3HTBqQc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SeekableUnicodeStreamReader.__del__ at 0x00000274F9302430>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yousef\\anaconda3\\lib\\site-packages\\nltk\\data.py\", line 1160, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\Yousef\\anaconda3\\lib\\site-packages\\nltk\\data.py\", line 1189, in close\n",
      "    self.stream.close()\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8f7d41c355e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0marticle_similarity_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title1_preprocessed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title1_en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title2_preprocessed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title2_en'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title1_preprocessed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title2_preprocessed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4ca8d1a82545>\u001b[0m in \u001b[0;36mpreprocess_title\u001b[1;34m(title)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Stem the remaining words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4ca8d1a82545>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Stem the remaining words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     21\u001b[0m         return [\n\u001b[0;32m     22\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file or directory: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate the distance between article titles\n",
    "# we can do this by finding the TF-IDF vectors for each title pair then finding the Euclidean distance between them\n",
    "article_similarity_data = []\n",
    "\n",
    "train_df['title1_preprocessed'] = train_df['title1_en'].apply(preprocess_title)\n",
    "train_df['title2_preprocessed'] = train_df['title2_en'].apply(preprocess_title) \n",
    "for pair in train_df.apply(lambda x: [x['title1_preprocessed'], x['title2_preprocessed']], axis=1):\n",
    "    vector_pair = vectorizer.fit_transform(pair).todense()\n",
    "    print(vector_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "wk-s2jRurLaG",
    "outputId": "765c7058-7528-4afd-ff63-e9074266a540"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_en</th>\n",
       "      <th>title2_en</th>\n",
       "      <th>label</th>\n",
       "      <th>title1_sentiment</th>\n",
       "      <th>title2_sentiment</th>\n",
       "      <th>title1_preprocessed</th>\n",
       "      <th>title2_preprocessed</th>\n",
       "      <th>article_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>There are two new old-age insurance benefits f...</td>\n",
       "      <td>Police disprove \"bird's nest congress each per...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>two new old-ag insur benefit old peopl rural a...</td>\n",
       "      <td>polic disprov `` bird 's nest congress person ...</td>\n",
       "      <td>1.326058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191474</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>`` come shenzhen , sooner later son also come ...</td>\n",
       "      <td>shenzhen 's gdp outstrip hong kong ? shenzhen ...</td>\n",
       "      <td>1.216096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25300</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>`` come shenzhen , sooner later son also come ...</td>\n",
       "      <td>gdp overtop hong kong ? shenzhen clarifi : lit...</td>\n",
       "      <td>1.227842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123757</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP overtakes Hong Kong? Bureau of ...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>`` come shenzhen , sooner later son also come ...</td>\n",
       "      <td>shenzhen 's gdp overtak hong kong ? bureau sta...</td>\n",
       "      <td>1.272112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141761</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n",
       "      <td>Shenzhen's GDP outpaces Hong Kong? Defending R...</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>`` come shenzhen , sooner later son also come ...</td>\n",
       "      <td>shenzhen 's gdp outpac hong kong ? defend rumo...</td>\n",
       "      <td>1.254330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  tid1  tid2                                          title1_en  \\\n",
       "0  195611     0     1  There are two new old-age insurance benefits f...   \n",
       "1  191474     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "2   25300     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "3  123757     2     8  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "4  141761     2    11  \"If you do not come to Shenzhen, sooner or lat...   \n",
       "\n",
       "                                           title2_en      label  \\\n",
       "0  Police disprove \"bird's nest congress each per...  unrelated   \n",
       "1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated   \n",
       "2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated   \n",
       "3  Shenzhen's GDP overtakes Hong Kong? Bureau of ...  unrelated   \n",
       "4  Shenzhen's GDP outpaces Hong Kong? Defending R...  unrelated   \n",
       "\n",
       "   title1_sentiment  title2_sentiment  \\\n",
       "0            0.3818               0.0   \n",
       "1            0.0000               0.0   \n",
       "2            0.0000               0.0   \n",
       "3            0.0000               0.0   \n",
       "4            0.0000               0.0   \n",
       "\n",
       "                                 title1_preprocessed  \\\n",
       "0  two new old-ag insur benefit old peopl rural a...   \n",
       "1  `` come shenzhen , sooner later son also come ...   \n",
       "2  `` come shenzhen , sooner later son also come ...   \n",
       "3  `` come shenzhen , sooner later son also come ...   \n",
       "4  `` come shenzhen , sooner later son also come ...   \n",
       "\n",
       "                                 title2_preprocessed  article_similarity  \n",
       "0  polic disprov `` bird 's nest congress person ...            1.326058  \n",
       "1  shenzhen 's gdp outstrip hong kong ? shenzhen ...            1.216096  \n",
       "2  gdp overtop hong kong ? shenzhen clarifi : lit...            1.227842  \n",
       "3  shenzhen 's gdp overtak hong kong ? bureau sta...            1.272112  \n",
       "4  shenzhen 's gdp outpac hong kong ? defend rumo...            1.254330  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['article_similarity'] = article_similarity_data\n",
    "train_df.to_csv('train-transformed.csv', index=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaQll4APtfoX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>title1_sentiment</th>\n",
       "      <th>title2_sentiment</th>\n",
       "      <th>article_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>256442.000000</td>\n",
       "      <td>256442.000000</td>\n",
       "      <td>256442.000000</td>\n",
       "      <td>256442.000000</td>\n",
       "      <td>256442.000000</td>\n",
       "      <td>256442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>128220.500000</td>\n",
       "      <td>85063.728434</td>\n",
       "      <td>69712.542399</td>\n",
       "      <td>-0.017322</td>\n",
       "      <td>-0.018051</td>\n",
       "      <td>1.279806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>74028.573203</td>\n",
       "      <td>48402.199542</td>\n",
       "      <td>45481.347050</td>\n",
       "      <td>0.437040</td>\n",
       "      <td>0.436707</td>\n",
       "      <td>0.169815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.991800</td>\n",
       "      <td>-0.999900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>64110.250000</td>\n",
       "      <td>44052.000000</td>\n",
       "      <td>30619.000000</td>\n",
       "      <td>-0.359500</td>\n",
       "      <td>-0.359500</td>\n",
       "      <td>1.222944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>128220.500000</td>\n",
       "      <td>85487.000000</td>\n",
       "      <td>63750.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.328323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>192330.750000</td>\n",
       "      <td>127504.000000</td>\n",
       "      <td>105255.750000</td>\n",
       "      <td>0.318200</td>\n",
       "      <td>0.318200</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>256441.000000</td>\n",
       "      <td>167563.000000</td>\n",
       "      <td>167557.000000</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           tid1           tid2  title1_sentiment  \\\n",
       "count  256442.000000  256442.000000  256442.000000     256442.000000   \n",
       "mean   128220.500000   85063.728434   69712.542399         -0.017322   \n",
       "std     74028.573203   48402.199542   45481.347050          0.437040   \n",
       "min         0.000000       0.000000       1.000000         -0.991800   \n",
       "25%     64110.250000   44052.000000   30619.000000         -0.359500   \n",
       "50%    128220.500000   85487.000000   63750.000000          0.000000   \n",
       "75%    192330.750000  127504.000000  105255.750000          0.318200   \n",
       "max    256441.000000  167563.000000  167557.000000          0.998600   \n",
       "\n",
       "       title2_sentiment  article_similarity  \n",
       "count     256442.000000       256442.000000  \n",
       "mean          -0.018051            1.279806  \n",
       "std            0.436707            0.169815  \n",
       "min           -0.999900            0.000000  \n",
       "25%           -0.359500            1.222944  \n",
       "50%            0.000000            1.328323  \n",
       "75%            0.318200            1.414214  \n",
       "max            0.998600            1.414214  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Attempted) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title1_sentiment</th>\n",
       "      <th>title2_sentiment</th>\n",
       "      <th>article_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.326058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.272112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unrelated</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.254330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  title1_sentiment  title2_sentiment  article_similarity\n",
       "0  unrelated            0.3818               0.0            1.326058\n",
       "1  unrelated            0.0000               0.0            1.216096\n",
       "2  unrelated            0.0000               0.0            1.227842\n",
       "3  unrelated            0.0000               0.0            1.272112\n",
       "4  unrelated            0.0000               0.0            1.254330"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train-transformed.csv').copy(deep=True).drop(labels=['id','tid1','tid2','title1_en','title2_en','title1_preprocessed','title2_preprocessed'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "# split your data into input features and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6412/6412 [==============================] - 6s 933us/step - loss: 0.9943 - accuracy: 0.5801 - val_loss: 0.9083 - val_accuracy: 0.6365\n",
      "Epoch 2/50\n",
      "6412/6412 [==============================] - 6s 920us/step - loss: 0.9555 - accuracy: 0.6390 - val_loss: 0.9014 - val_accuracy: 0.6242\n",
      "Epoch 3/50\n",
      "6412/6412 [==============================] - 6s 937us/step - loss: 0.9492 - accuracy: 0.6307 - val_loss: 0.8277 - val_accuracy: 0.6736\n",
      "Epoch 4/50\n",
      "6412/6412 [==============================] - 6s 935us/step - loss: 0.9437 - accuracy: 0.6249 - val_loss: 0.8682 - val_accuracy: 0.6295\n",
      "Epoch 5/50\n",
      "6412/6412 [==============================] - 6s 920us/step - loss: 0.9408 - accuracy: 0.6142 - val_loss: 0.8628 - val_accuracy: 0.6207\n",
      "Epoch 6/50\n",
      "6412/6412 [==============================] - 6s 951us/step - loss: 0.9386 - accuracy: 0.6047 - val_loss: 0.8869 - val_accuracy: 0.5926\n",
      "Epoch 7/50\n",
      "6412/6412 [==============================] - 6s 943us/step - loss: 0.9381 - accuracy: 0.5991 - val_loss: 0.8671 - val_accuracy: 0.6089\n",
      "Epoch 8/50\n",
      "6412/6412 [==============================] - 6s 937us/step - loss: 0.9378 - accuracy: 0.5946 - val_loss: 0.8573 - val_accuracy: 0.6065\n",
      "Epoch 9/50\n",
      "6412/6412 [==============================] - 6s 924us/step - loss: 0.9359 - accuracy: 0.5908 - val_loss: 0.8369 - val_accuracy: 0.6061\n",
      "Epoch 10/50\n",
      "6412/6412 [==============================] - 6s 940us/step - loss: 0.9368 - accuracy: 0.5904 - val_loss: 0.8425 - val_accuracy: 0.6221\n",
      "Epoch 11/50\n",
      "6412/6412 [==============================] - 6s 927us/step - loss: 0.9361 - accuracy: 0.5907 - val_loss: 0.9037 - val_accuracy: 0.5782\n",
      "Epoch 12/50\n",
      "6412/6412 [==============================] - 6s 929us/step - loss: 0.9361 - accuracy: 0.5883 - val_loss: 0.8685 - val_accuracy: 0.6022\n",
      "Epoch 13/50\n",
      "6412/6412 [==============================] - 6s 929us/step - loss: 0.9357 - accuracy: 0.5883 - val_loss: 0.8086 - val_accuracy: 0.6335\n",
      "Epoch 14/50\n",
      "6412/6412 [==============================] - 6s 961us/step - loss: 0.9356 - accuracy: 0.5890 - val_loss: 0.8552 - val_accuracy: 0.6036\n",
      "Epoch 15/50\n",
      "6412/6412 [==============================] - 6s 941us/step - loss: 0.9358 - accuracy: 0.5908 - val_loss: 0.9630 - val_accuracy: 0.5351\n",
      "Epoch 16/50\n",
      "6412/6412 [==============================] - 7s 1ms/step - loss: 0.9355 - accuracy: 0.5860 - val_loss: 0.9382 - val_accuracy: 0.5623\n",
      "Epoch 17/50\n",
      "6412/6412 [==============================] - 6s 950us/step - loss: 0.9352 - accuracy: 0.5875 - val_loss: 0.8558 - val_accuracy: 0.5938\n",
      "Epoch 18/50\n",
      "6412/6412 [==============================] - 6s 919us/step - loss: 0.9347 - accuracy: 0.5853 - val_loss: 0.8400 - val_accuracy: 0.6151\n",
      "Epoch 19/50\n",
      "6412/6412 [==============================] - 6s 949us/step - loss: 0.9347 - accuracy: 0.5886 - val_loss: 0.9225 - val_accuracy: 0.5387\n",
      "Epoch 20/50\n",
      "6412/6412 [==============================] - 6s 1ms/step - loss: 0.9346 - accuracy: 0.5826 - val_loss: 0.8657 - val_accuracy: 0.5898\n",
      "Epoch 21/50\n",
      "6412/6412 [==============================] - 6s 936us/step - loss: 0.9340 - accuracy: 0.5837 - val_loss: 0.8582 - val_accuracy: 0.6001\n",
      "Epoch 22/50\n",
      "6412/6412 [==============================] - 6s 940us/step - loss: 0.9341 - accuracy: 0.5839 - val_loss: 0.8803 - val_accuracy: 0.5764\n",
      "Epoch 23/50\n",
      "6412/6412 [==============================] - 6s 949us/step - loss: 0.9337 - accuracy: 0.5795 - val_loss: 0.9193 - val_accuracy: 0.5318\n",
      "Epoch 24/50\n",
      "6412/6412 [==============================] - 6s 926us/step - loss: 0.9340 - accuracy: 0.5846 - val_loss: 0.8967 - val_accuracy: 0.5611\n",
      "Epoch 25/50\n",
      "6412/6412 [==============================] - 6s 931us/step - loss: 0.9340 - accuracy: 0.5882 - val_loss: 0.8678 - val_accuracy: 0.6093\n",
      "Epoch 26/50\n",
      "6412/6412 [==============================] - 6s 937us/step - loss: 0.9339 - accuracy: 0.5888 - val_loss: 0.8955 - val_accuracy: 0.5653\n",
      "Epoch 27/50\n",
      "6412/6412 [==============================] - 6s 933us/step - loss: 0.9339 - accuracy: 0.5866 - val_loss: 0.9423 - val_accuracy: 0.5255\n",
      "Epoch 28/50\n",
      "6412/6412 [==============================] - 6s 917us/step - loss: 0.9336 - accuracy: 0.5848 - val_loss: 0.8307 - val_accuracy: 0.6238\n",
      "Epoch 29/50\n",
      "6412/6412 [==============================] - 6s 924us/step - loss: 0.9332 - accuracy: 0.5872 - val_loss: 0.9046 - val_accuracy: 0.5810\n",
      "Epoch 30/50\n",
      "6412/6412 [==============================] - 6s 936us/step - loss: 0.9330 - accuracy: 0.5844 - val_loss: 0.8317 - val_accuracy: 0.6307\n",
      "Epoch 31/50\n",
      "6412/6412 [==============================] - 6s 935us/step - loss: 0.9333 - accuracy: 0.5861 - val_loss: 0.8908 - val_accuracy: 0.5710\n",
      "Epoch 32/50\n",
      "6412/6412 [==============================] - 6s 929us/step - loss: 0.9334 - accuracy: 0.5827 - val_loss: 0.9065 - val_accuracy: 0.5718\n",
      "Epoch 33/50\n",
      "6412/6412 [==============================] - 6s 934us/step - loss: 0.9329 - accuracy: 0.5857 - val_loss: 0.8944 - val_accuracy: 0.5643\n",
      "Epoch 34/50\n",
      "6412/6412 [==============================] - 6s 928us/step - loss: 0.9332 - accuracy: 0.5844 - val_loss: 0.9450 - val_accuracy: 0.5603\n",
      "Epoch 35/50\n",
      "6412/6412 [==============================] - 6s 960us/step - loss: 0.9332 - accuracy: 0.5885 - val_loss: 0.9219 - val_accuracy: 0.5409\n",
      "Epoch 36/50\n",
      "6412/6412 [==============================] - 6s 929us/step - loss: 0.9331 - accuracy: 0.5847 - val_loss: 0.9273 - val_accuracy: 0.5674\n",
      "Epoch 37/50\n",
      "6412/6412 [==============================] - 6s 951us/step - loss: 0.9334 - accuracy: 0.5862 - val_loss: 0.8786 - val_accuracy: 0.5790\n",
      "Epoch 38/50\n",
      "6412/6412 [==============================] - 6s 985us/step - loss: 0.9330 - accuracy: 0.5834 - val_loss: 0.9084 - val_accuracy: 0.5711\n",
      "Epoch 39/50\n",
      "6412/6412 [==============================] - 6s 957us/step - loss: 0.9330 - accuracy: 0.5842 - val_loss: 0.8523 - val_accuracy: 0.5924\n",
      "Epoch 40/50\n",
      "6412/6412 [==============================] - 6s 985us/step - loss: 0.9327 - accuracy: 0.5860 - val_loss: 0.7998 - val_accuracy: 0.6351\n",
      "Epoch 41/50\n",
      "6412/6412 [==============================] - 6s 946us/step - loss: 0.9326 - accuracy: 0.5870 - val_loss: 0.9095 - val_accuracy: 0.5579\n",
      "Epoch 42/50\n",
      "6412/6412 [==============================] - 6s 937us/step - loss: 0.9328 - accuracy: 0.5856 - val_loss: 0.8592 - val_accuracy: 0.5945\n",
      "Epoch 43/50\n",
      "6412/6412 [==============================] - 6s 951us/step - loss: 0.9325 - accuracy: 0.5843 - val_loss: 0.8665 - val_accuracy: 0.6071\n",
      "Epoch 44/50\n",
      "6412/6412 [==============================] - 6s 940us/step - loss: 0.9326 - accuracy: 0.5854 - val_loss: 0.8728 - val_accuracy: 0.5734\n",
      "Epoch 45/50\n",
      "6412/6412 [==============================] - 6s 935us/step - loss: 0.9323 - accuracy: 0.5834 - val_loss: 0.8292 - val_accuracy: 0.6163\n",
      "Epoch 46/50\n",
      "6412/6412 [==============================] - 6s 934us/step - loss: 0.9327 - accuracy: 0.5834 - val_loss: 0.8706 - val_accuracy: 0.5949\n",
      "Epoch 47/50\n",
      "6412/6412 [==============================] - 6s 928us/step - loss: 0.9324 - accuracy: 0.5846 - val_loss: 0.9449 - val_accuracy: 0.5226\n",
      "Epoch 48/50\n",
      "6412/6412 [==============================] - 6s 952us/step - loss: 0.9323 - accuracy: 0.5812 - val_loss: 0.8559 - val_accuracy: 0.5872\n",
      "Epoch 49/50\n",
      "6412/6412 [==============================] - 6s 949us/step - loss: 0.9320 - accuracy: 0.5839 - val_loss: 0.8285 - val_accuracy: 0.6238\n",
      "Epoch 50/50\n",
      "6412/6412 [==============================] - 6s 946us/step - loss: 0.9323 - accuracy: 0.5791 - val_loss: 0.9205 - val_accuracy: 0.5519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a142d18310>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('label', axis=1).values\n",
    "y = to_categorical([0 if l == 'unrelated' else 1 if l == 'agreed' else 2 for l in df['label'].values])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# calculate class weights\n",
    "classes = np.unique(np.argmax(y_train, axis=1))\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=[0,1,2], y=y_train.argmax(axis=1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), class_weight=dict(enumerate(class_weights)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603/1603 [==============================] - 1s 566us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a1480cbbe0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAs+0lEQVR4nO3deXxU1fn48c+THcK+CkmQRUBZBCoiuEKxilqLtlpBLbTaL0q1aqu1Lr+KVam1aq22FUWlirsVNxRUVBS1KAIubAJhDwkEEhKSAFlmnt8f906Y7DNhJpmZPO/X675y59zt3CE8Ocu954iqYowxxhHX3BkwxphIYkHRGGP8WFA0xhg/FhSNMcaPBUVjjPGT0NwZ8NelU7z2zkhs7mxErHU7uzZ3FiJeRao9TVGfirx9eIpL5EjOcfa4VM3L9wS074rvSt9T1QlHcr2mFlFBsXdGIsvey2jubESsUbdOb+4sRLw9JwX2n7Wl2nXvw0d8jrx8D8ve6xXQvvE9NnY54gs2sYgKisaYyKeAF29zZyNsLCgaY4KiKOUauyVyC4rGmKBZSdEYY1yK4onh14MtKBpjgubFgqIxxgBOR4vHgqIxxhxmJUVjjHEpUG5tisYY41DUqs/GGFNJwRO7MdGCojEmOM4bLbHLgqIxJkiChyMaUyKiWVA0xgTF6WiJ3aBo4ykaY4LiPKcoAS0NEZE5IpIrIqv90l4WkW/cZauIfOOm9xaRg37bHvM75gQRWSUimSLyiIiIm57sni9TRL4Ukd4N5clKisaYoHlDV1J8GvgXMNeXoKqX+NZF5EGg0G//Tao6vJbzzAKmAV8AC4AJwELgSmCfqh4jIpOA+4BLajm+kpUUjTFBCWVJUVWXAPm1bXNLez8HXqzvHCLSA2inqkvVmbN5LnCBu3ki8Iy7/iow3leKrIsFRWNMUBTBQ1xAC9BFRJb7LdOCuNRpwG5V3eiX1kdEvhaRT0TkNDctDcjy2yfLTfNt2wGgqhU4pc7O9V3Uqs/GmKAFUX3eq6ojG3mZyVQtJeYAvVQ1T0ROAN4QkcFQa5HU9yRlfdtqZUHRGBMURSjT+LBeQ0QSgJ8CJ1ReV7UUKHXXV4jIJmAATskw3e/wdCDbXc8CMoAs95ztqaO67mPVZ2NMUJyHt+MCWo7AmcD3qlpZLRaRriIS7673BfoDm1U1BygSkdFue+EU4E33sLeAqe76RcBHbrtjnaykaIwJWqge3haRF4GxOG2PWcAMVX0KmETNDpbTgbtEpALwAFerqq/UNx2nJ7sVTq/zQjf9KeBZEcnEKSFOaihPFhSNMUFRFTwamkqmqk6uI/2XtaTNA+bVsf9yYEgt6YeAi4PJkwVFY0zQvPaanzHGOJyOltgNHbF7Z8aYsPB1tMQqC4rGmKB5YnhACAuKxpig+N5oiVUWFI0xQfOGqPc5EllQNMYExRkQwoKiMcYATvW5PMyv+TWnmA+KD/4ugy8/aEeHLhXMXrwegE2rW/HILemUHYojPkG59t4sjh1xgPIy4eGb09n4XWskDqbftZNhJxcD8PGbHXjpke54PHDS+P38+k85ADw2oyffft4WgNJDQsHeRF77flXz3GwItEkp5faffkK/7vkocM+8sWzb04GZkxfRo2MROfvactsLZ1F0KJn2rQ9x76XvMyg9l7dXDuSBt06rPM+xPfdwx8WLSU6s4H/re/Hg/FOo/d38yNb92c2krirA0zaRbX8aesTna/fFHjotdF7LzT+nJ/tHd62yvevLW2n/xV4yH2rsGArhp0rIHt6ORGG9MxGZICLr3VFvbwnntepy1iX5zHx+c5W0J+/pweW/38WsD9Yz5Q85PHVPTwAWPu+MKPT4R+v560ubmP3nnni9sD8/nifv7slfX8nkiY/Xs29vIl9/2gaAq/+czawP1jPrg/VM/NVeTjmnoEnvL9RuPP9zvtiQwc8fmsRlj1zMltyOTD3ja77alM5FD17KV5vSmTr2awBKy+N5fNGJPLJgTI3z/PGCJdz7+un87IHJZHQuZMyAHU19KyGxf3QXdl47MOjj0h9aR0JeaZW0uJIKOr2TzfabB7P9j4Pp9E42cQcqKrcnbysm/qDniPMcfoI3wCUahS0oui9u/xs4BxgETBaRQeG6Xl2Gji6hbceqv2giUFLkFP9L9sfTqXs5ANs3JDPiNKdk2KFLBW3ae9jwbWtytieR1reUDp2d84w4rYjPFnSoca3Fb3Rk7AX7wng34ZWaXMaI3jm8ufxYACo88RQfSub0QVt5Z+UAAN5ZOYAzBm0B4FB5It9u60FpRdWqVOe2JaQml7Nq+1GAsODrw8dEm4P92+FJrVqhStxziLR/rafXvatJf3AtibsOBnSu1LWFHDiuHd7UBLytEzhwXDtS17iDSnuVrq/tYM+FGaG+hZBTnJJiIEs0Cmf1eRSQqaqbAUTkJZxRcNeG8ZoBufqundw2uR9P3NUTVXjoLWcMy76DD7H0vfaMnbiPPdlJbPyuNXuyExl+SjFZm5LZtSOJrj3K+N+77akoq/pXcHdWIrt3JDH81OLmuKWQ6NlpP/tKUrjjosX075HH9zu78uD8U+jU5iB5RakA5BWl0rFN/UGgW7sScvenVn7OLWxDt/YlYc17U+r+wlZ2T+5NebcUUrYU0/2lrWTdcFyDxyUUlFHRManyc0WHJBIKygDo8PFuio/viKd9Ul2HRxTraGmcyhFvXVnASWG8XsDefqYLV/15J6edV8gnb3Xg77/vxX2vbOLsSXls35jMtRMG0i29jEEjS4iPV9p28PDbe7P4y9VHExcHx40sYde2qr+8H7/RkVPPKyA+itufE+K8DOy5lwfmn8qaHd35/Y8/q6wqB6WWWpPGyMO+cshDyuYiejyZeTit3JkFud3SPXRYvBuApD2HSPv3ejQhjorOyWRf1b+OE0J8QRltv85nRwCBNRIoEso5WiJOOINiQCPeusOTTwPoldY0/T6L/tuJ6XfvBOD08wv4x01OlSU+wWkj9Lnh/P6k9XXahUaftZ/RZ+0HYMFznYmPq3orn7zZgWv+kkU0yy1sQ+7+VNbs6A7AR6v7MeWMr8kvbkXntiXkFaXSuW0J+4pbNXCeVLq1O1wy7Na+mD37W4c1701FFLytEth+W40BWdg/piv7xzgdJ+kPrWPXlL5UdE6u3F7RIYlWG/dXfk4oKONg/3ak7DhA4p5S+sz41rlGmZfeM75l65+HhfluGseZ4jR2+2jDWQb2jXjr4z8abiVVna2qI1V1ZNfOTVPM6ty9nO+WOh0l33zWhp59nMB36IBw6IDzlaz4pA3xCcrRA5xtBXudX4KignjmP92FCZceHrx3R2YyxYUJDBp5oEnyHy55xa3JLWhDry4FAJzYL4stuR1Zsq435/1gAwDn/WADS9b2rv88RakcKEtkSMZuQDl3xAaWrKv/mGjhbRVPeedk2qx0//1VScoK7N+9ZFB7UtcVEneggrgDFaSuK6RkUHtKhnZg819HsOWe4Wy5ZziaFBexAdER2KRVoRpzsamFM9x/BfQXkT7ATpzBHS8N4/Vqde/0o/luaRsK8xO47IRB/OLGXdxw/w5m3ZGGxyMkJXu54X6nll+Ql8jtk/sicdD5qHJu/ue2yvPM+lMam9c6JaTLfreL9H6HexY/fqMjZ0zcR/1zhEWH++efyt2XfEhCvIfs/Hbc9eo44uKUv0xexE9GrmN3QVtufeFHlfu/cfNzpCaXkxjv4YxBW7luznlsye3EfW+cxh0XLSY50cP/NmTwv/W9mvGuGu+oOZm03lBEfHEFfW77mrzz0sn5VT+6v7SVzgt3gkcpGtmZ/PSGS8Le1ATyzkmj131rAMg7Nw1vavSVuJTYfqNFGhiZ+8hOLnIu8A8gHpijqjPr23/ksBRd9l7k9741l1G3Tm/uLES8PSdFwyMtzWfXvQ9Tui3riP58pw9pr9e8ckpA+942eOGKI5i4qlmE9c+Uqi7AmZjaGBMjVCWmS4rRV3Y3xjQrp6Mlih+zaIAFRWNMkEI3R0skit07M8aEhdPRIgEtDRGROSKSKyKr/dLuFJGdIvKNu5zrt+1W97Xh9SJytl/6CSKyyt32iDvVKSKSLCIvu+lfikjvhvJkQdEYEzQPcQEtAXgamFBL+kOqOtxdFgC4rwlPAga7xzzqmwcamIXzvHN/d/Gd80pgn6oeAzwE3NdQhiwoGmOC4nujJRQlRVVdgjMfcyAmAi+paqmqbgEygVEi0gNop6pL3Ynu5wIX+B3zjLv+KjDeV4qsiwVFY0zQvMQFtOBMcr/cb5kW4CWuFZHv3Op1RzettleH09wlq5b0KseoagVQCHSu78LW0WKMCYoqlHsDLk/tbcRzirOAu3GaL+8GHgSuoO5Xh+t7pTig1439WVA0xgTFqT6Hr5Kpqrt96yLyBPC2+7GuV4ez3PXq6f7HZIlIAtCeBqrrVn02xgQtnO8+u22EPhcCvp7pt4BJbo9yH5wOlWWqmgMUichot71wCvCm3zFT3fWLgI+0gdf4rKRojAmK75GcUBCRF4GxOG2PWcAMYKyIDHcvtRW4CkBV14jIKzhjslYA16iq773O6Tg92a2Ahe4C8BTwrIhk4pQQJzWUJwuKxpggha76rKqTa0l+qp79ZwI1xlBQ1eVAjfHcVPUQcHEwebKgaIwJWrTOvxIIC4rGmKA4vc/27rMxxgA2HYExxtRg1WdjjHGFsvc5EllQNMYEzQaZNcYYl6pQYUHRGGMOs+qzMca4rE3RGGOqsaBojDEue07RGGOqsecUjTHGpQoVgQ8yG3UsKBpjgmbVZ2OMcVmbojHGVKMWFI0x5jDraDHGGJeqtSkaY4wfwWO9z8YYc5i1KTaRjWvbce6Is5o7GxGr8NrmzkHk67WguXMQ2fILj/wcIZ7Nbw7wYyBXVYe4afcD5wNlwCbgV6paICK9gXXAevfwL1T1aveYEzg8m98C4HpVVRFJBuYCJwB5wCWqurW+PMVuGdgYEx7qtCsGsgTgaWBCtbRFwBBVPR7YANzqt22Tqg53l6v90mcB03Dmgu7vd84rgX2qegzwEHBfQxmyoGiMCZoXCWhpiKouwZmP2T/tfVWtcD9+AaTXdw4R6QG0U9Wl7kT3c4EL3M0TgWfc9VeB8SJSb8YsKBpjgqJuR0sgC84k98v9lmlBXu4KDk9sD9BHRL4WkU9E5DQ3LQ3I8tsny03zbdsB4AbaQqBzfReMqDZFY0x0CLBqDLBXVUc25hoicjtQATzvJuUAvVQ1z21DfENEBkOtRVJfDuvbVisLisaYoIW791lEpuJ0wIx3q8SoailQ6q6vEJFNwACckqF/FTsdyHbXs4AMIEtEEoD2VKuuV2fVZ2NMUJxOFAloaQwRmQD8EfiJqh7wS+8qIvHuel+cDpXNqpoDFInIaLe9cArwpnvYW8BUd/0i4CNfkK2LlRSNMUEL4SM5LwJjcdoes4AZOL3NycAit0/E9+jN6cBdIlIBeICrVdVX6pvO4UdyFnK4HfIp4FkRycQpIU5qKE8WFI0xQQuiTbGB8+jkWpKfqmPfecC8OrYtB4bUkn4IuDiYPFlQNMYERRG89pqfMcYcFqKCYkSyoGiMCY7au8/GGFNVDBcVLSgaY4LWIkuKIvJP6vl7oKrXhSVHxpiIpoDX2wKDIrC8yXJhjIkeCrTEkqKqPuP/WURSVbUk/FkyxkS6UD2nGIkafNhIRMaIyFqcwR0RkWEi8mjYc2aMiVwa4BKFAnkC8x/A2Tij1qKq3+K8bmOMaZECe+85WjtjAup9VtUd1cZl9IQnO8aYqBClpcBABBIUd4jIyYCKSBJwHW5V2hjTAiloDPc+B1J9vhq4BmcE253AcPezMabFkgCX6NNgSVFV9wKXNUFejDHRIoarz4H0PvcVkfkiskdEckXkTXeAR2NMS9XCe59fAF4BegA9gf8CL4YzU8aYCOZ7eDuQJQoFEhRFVZ9V1Qp3eY6o/RtgjAmFEM77HHHqe/e5k7u6WERuAV7CCYaXAO80Qd6MMZEqhnuf6+toWYETBH13f5XfNgXuDlemjDGRTaK0FBiI+t597tOUGTHGRIko7kQJREATLYjIEBH5uYhM8S3hzpgxJlIF2MkSQEeLiMxxn2pZ7ZfWSUQWichG92dHv223ikimiKwXkbP90k8QkVXutkfcqU4RkWQRedlN/1JEejeUp0AeyZkB/NNdxgF/A37S4N0aY2JX6B7JeRqYUC3tFuBDVe0PfOh+RkQG4UxROtg95lHfPNDALGAazlzQ/f3OeSWwT1WPAR4C7msoQ4GUFC8CxgO7VPVXwDCcOVmNMS2VN8ClAaq6BGc+Zn8TAd/Qhc8AF/ilv6Sqpaq6BcgERolID6Cdqi51J7qfW+0Y37leBcb7SpF1CeTd54Oq6hWRChFpB+QCUfnw9g0z1jDq9D0U5Cfxm4tPrrLtp7/Yyq9/v5FJ485gf0FSZXrXow7y2LylPP9YX157tjcAU67JZPyPs2nTroKfnfLDpryFsJs6+FsuHvg9CmzI78ytn46lzJPA5YNWcflxq6nQOD7Z0Yv7vxrD+f02cOXQbyuPHdgpjwvfuIithe15ePwierXdj0eFxduP5sHlo5vvpkIsTrzMvv0N9hS05tZ/OQWSn45bzYXj1uLxCl+s6sVj807izFGZTDr78PfTLy2f/7vnp2RmdeYfN75N5/YHKC13Cjo3/eNcCopaNcv9BC24QWa7iIj/gNWzVXV2A8d0V9UcAFXNEZFubnoa8IXfflluWrm7Xj3dd8wO91wVIlIIdAb21nXxQILichHpADyB0yNdDCxr6CARmQP8GMhV1RqTVDeHD+b3ZP7LGdx49+oq6V26H2LE6Hxyc1JqHDPtpg0s/7xzlbQvl3Rh/ssZPPnm52HNb1Pr1rqYKYNXc+68Syj1JPCPce9zXt9MsovbMr7XVs5//eeUe+PplHIQgPmbBjB/0wAABnTM49Ez3+X7/C6kxJczZ9UwvsxJIzHOw9PnzOf09O0syerVnLcXMheNX822nA60blUGwIiB2ZwyfBtX3PUzyivi6dDW+X4+WHYMHyw7BoC+afnM/M37ZGYd/l2656lxrN/WtelvIASC6H3eq6ojQ3XZWtK0nvT6jqlTg9VnVf2Nqhao6mPAj4CpbjW6IU9Ts62gWa1e2ZGiwsQa6dNuWs+ch/vXeNh0zNhccrJasX1Tmyrp61d1YN/e2GxBiBcvKfEVzs+ECnIPpDL52DXM/m4E5V6nVJN/qGaJ5ry+mby92QkAhzyJfJnj/KEu98azNq8L3VOLm+4mwqhrh2JGD93B258NrEybeMZaXnh3OOUVzvdTW4lv/Imb+PCrfk2Wz7AL72t+u90qMe7PXDc9C8jw2y8dyHbT02tJr3KMiCQA7alZXa+izqAoIj+ovgCdgAR3vV51tBVEnJPOyCUvN5ktG9pWSU9O8XDRr7bywuNR2VLQKLkH2jBn9TAWT3qOzybPpbgsic93ZtC7fSEju+fwyvmv8ey5bzK0S26NY8/tu4l3Nvevkd42qZRxGdtYmp1eY1s0uvaSL3hs3qgqA6imdy/k+GN2MevWN3j4pvkce/SeGseNO3ETHy6rGhRv+eUnPPmneUw5byUx/YxL8N4CprrrU4E3/dInuT3KfXA6VJa5Ve0iERntthdOqXaM71wXAR+57Y51qq/6/GA92xQISWOaiEzD6TUiJa5NA3uHVnKKh0lXbuH239SM8ZdP38Qbz/Xi0MGWMwtsu6RSxvfayvhXLqOoNImHxy/iJ/02EB/npV1yKT+ffyFDu+Tyjx8uYvwrl+KrmRzfdTcHKxLYuK9TlfPFi5e/j/2AZ9cOJauoXTPcUWiNGbqNgqIUNmzvyvAB2ZXp8XFK29alTL93Isf23sOdV33ApNsm4ft+juuTS2lZAluyD38/9zw1jr0FqbRKLuPu6R9w9uiNvPfFgKa+pUYL1cPbIvIiMBan7TELmAH8FXhFRK4EtgMXA6jqGhF5BVgLVADXqKpvwOvpOLXTVsBCdwF4CnhWRDJxCmmTGspTfQ9vjwvy/hrFbXSdDdA+sVuT/rnskX6A7mkH+ffLTtttl26lPPLCl/zuF6MYOKSQU8/czRU3bCS1bQXqhbKyON5+OTbaxWpzcs8ssorasc+tHr+/tQ8juu9id0kbFm3tAwir9nbHq0LHlEOV+53XN5N33Kqzv7tP/YSt+9vzzJrjm/I2wmbIMbs5edh2ThryIkmJHlJblXH7FYvZsy+VJV/3BoTvt3bDq0L7NocoLHa+nx/WUkrcW5AKwMHSJD748hiO7bMneoKiErLX/FR1ch2bxtex/0xgZi3py4EafReqegg3qAaq5RSDarE1sy2Xjh9b+fk/73zK9ZedxP6CJG6+8sTK9Muu2sTBA/ExHRABskvaMKzbblLiyznkSWBMz52s3tuV9fmdGd0zm2W70ujdroDEOA/7DjmdUoIyoc9mLntnYpVz3XDCMtoklnH7p2Ob4U7C44nXR/HE66MAGD4gm0vO+o6Zc8bxk9PX8oNjs/lmQ0/SuxWQGO+lsNj9fkQZe8IWrrv/x5XniY/z0qZ1GYXFKcTHexlz/HZWrOvZLPfUaDFc229RQfHme7/j+BP20a5DOXPfXcJzj/Xj/TfSGj6wmiuu38DYc3aRnOJh7rtLeO/1NJ5/PPob0b/b0533tvTl9QvmUaHCurwuvPz9IAD+ctrHzP/py5R74rllyQ/xVQ1PPCqbXSWpVarH3VsXM334SjYVdOD1C14F4Lm1Q3h1w3FNfk9NYcHnA/nj1CX8Z8arVHji+Mt/zsD3/Qzrn8Oefank7D38/SQmeLj/+oUkxHuJi/OyYl0ab396bDPlvnFi+d1naaDNsfEn9msrAHYDM1T1qfqOaZ/YTcd0Caqk26Jsujb6A2+4HfWlzalWn2+WPExRQdYR1X2TMzI0/YbfBbTv5ptuXBHCR3KaRIMlRbc35zKgr6reJSK9gKNUtd5nFetpKzDGRLsYLikG8prfo8AYwBfkioB/hy1HxpiIJhr4Eo0CaVM8SVV/ICJfA6jqPneqU2NMS9VCB5n1KXdHolAAEelKQK96G2NiVbSWAgMRSPX5EeB1oJuIzAQ+A/4S1lwZYyJbDM/mF8i8z8+LyAqchykFuEBV14U9Z8aYyBTF7YWBCKT3uRdwAJjvn6aq28OZMWNMBGvJQRFn5j7f8DwpQB9gPc7ot8aYFkhiuFchkOrzUP/P7gg5V9WxuzHGRLWgX/NT1ZUicmLDexpjYlZLrj6LyO/9PsYBPwBqDhhnjGkZWnpHC+A/+moFThvjvPBkxxgTFVpqUHQf2m6jqn9oovwYY6JBSwyKIpLgzn7V4NQDxpiWQ2i5vc/LcNoPvxGRt4D/AiW+jar6WpjzZoyJRNamSCcgD2dOFt/zigpYUDSmpWqhQbGb2/O8mppzq8bwV2KMaVAIIoCIDARe9kvqC9wBdAD+j8NPudymqgvcY24FrgQ8wHWq+p6bfgKHJ65aAFzf0Kx9dakvKMYDbWjEZNLGmNgWiuqzqq4HhkNlp+5OnMFnfgU8pKoPVLmmyCCc2fgGAz2BD0RkgDuj3yycWUG/wAmKEzg8o19Q6guKOap6V2NOaoyJcaEvFo0HNqnqNmew/1pNBF5S1VJgiztt6SgR2Qq0U9WlACIyF7iARgbF+oYOi91RJI0xjadO73MgSxAmAS/6fb5WRL4TkTki0tFNSwN2+O2T5aaluevV0xulvqBY67yrxhgTxHiKXURkud8yrfqp3JH8f4LzhAs4VeF+OFXrHOBB36515CSkTXx1Vp9VNb+xJzXGxLYg2hT3BjCb3znASlXdDeD7CSAiTwBvux+zgAy/49KBbDc9vZb0Rglk5G1jjKkqtCNvT8av6iwiPfy2XYjzBAzAW8AkEUkWkT5Af2CZquYARSIy2p19dArwZuNurBGj5BhjWrgQTjUgIq2BH1F1OMK/ichw9ypbfdtUdY2IvAKsxRmH4Rq35xlgOocfyVlIIztZwIKiMSZIQujeaFHVA0Dnamm/qGf/mcDMWtKXA0NCkScLisaYoLX01/yMMaYqC4rGGOPHgqIxxrhslBxjjKnGgqIxxhzWUgeZbXJaUYFnd25zZyNi9Z6R19xZiHiSGFG/0hFHSg+G5jxWUjTGGFcIH96ORBYUjTHBs6BojDGOUL7REoksKBpjgibe2I2KFhSNMcGxNkVjjKnKqs/GGOPPgqIxxhxmJUVjjPFnQdEYY1xqr/kZY0wle07RGGOq09iNihYUjTFBi+WSok1xaowJTqDTmwYQOEVkq4isEpFvRGS5m9ZJRBaJyEb3Z0e//W8VkUwRWS8iZ/uln+CeJ1NEHnGnOm0UC4rGmKCJN7AlQONUdbiqjnQ/3wJ8qKr9gQ/dz4jIIGASMBiYADwqIvHuMbOAaThzQfd3tzeKBUVjTNBCHBSrmwg8464/A1zgl/6Sqpaq6hYgExglIj2Adqq6VFUVmOt3TNAsKBpjgqM4HS2BLIGd7X0RWSEi09y07qqaA+D+7OampwE7/I7NctPS3PXq6Y1iHS3GmKAF0dHSxddW6JqtqrP9Pp+iqtki0g1YJCLf13fZWtK0nvRGsaBojAle4CFnr19bYc3TqGa7P3NF5HVgFLBbRHqoao5bNfbNUZIFZPgdng5ku+nptaQ3ilWfjTFB8T28HchS73lEUkWkrW8dOAtYDbwFTHV3mwq86a6/BUwSkWQR6YPTobLMrWIXichot9d5it8xQbOSojEmOKqhGmS2O/C6+/RMAvCCqr4rIl8Br4jIlcB24GLnsrpGRF4B1gIVwDWq6nHPNR14GmgFLHSXRrGgaIwJXghioqpuBobVkp4HjK/jmJnAzFrSlwNDjjxXFhSNMY0Qy2+0WFA0xgRHAZujxRhj/MRuTLSgaIwJnlWfjTHGj01xaowxPjbFqTHGHOY8vB27UdGCojEmeDZHizHGHGYlxRjUtWcZf3h4Ox27VaBeWPBcZ954qmvl9ouuzuX/7sjh4iGD2Z+fwMDhB7j+fmfUIgGeffAo/vdu+2bKfdOJi1P+ueB78nYlcscvj2HKTdmMObsA9QoFexN44PdHk787ie7ppTzx8VqyNqUA8P3KVB65tVcz5z78UttWcMN9W+g94CCq8NDNfThxXCFjfrQPr1coyEvgwZv6kp+bRHyClxv+uoVjBh8gPkH58LUuvDyrZ3PfQvCsTbFxRCQDZ7DHo3AK27NV9eFwXS9Yngph9l09yVzVmlapHv717gZWLmnL9o0pdO1ZxojTi9idlVi5/9b1KVw7YQBej9CpWzmzPtjAF4va4fU0etTzqHDBlbnsyEyhdRvnFdNXH+vO3Aec/8gTr8jl8ht2VQa/nK3J/Obs45otr83h6hnbWPFJe2b+pj8JiV6SU7xs29iauX93Bm2Z+MtdXHbdTv75//pw2rn5JCYp088ZSnKKh9mLVvHxW53ZvTO5me8iWCF79zkihXOUnArgRlU9DhgNXOMOJx4R8nMTyVzVGoCDJfHsyEyhS49yAK66M5un7ulZZYzM0oNxlQEwMdkby5OZVerSo4xR4/ez8IUulWkHiuMr11NatYzvoS6t23gYOqqId192ahgV5XGUFCXU8h25fzhVSGntJS5eSUrxUl4ulPjtG1VCN8hsxAlbSdEdzsc3em6RiKzDGQ13bbiu2Vjd08voN+Qg369szeizCtm7K5HNa1vV2G/giBJu/PsOuqWX87ff9or5UuLVd2bx5My0ylKizy9v3smZF+VTsj+em3/evzL9qF5l/PvddRwojueZv/Vk9bI2TZ3lJnVUxiEK8xO58f4t9DnuAJmrU5n1516UHoxn6k07OPPCPEqK4vnjpccC8OnCjoz+0T5e+PJrUlp5efyeXhQXRmELlh7RVAMRr0nGUxSR3sAI4MumuF4wUlp7+NOTW3nsjp54PMLk63KZe/9Rte67/utUpo07lt+e059Jv91NYnLs/macNL6Qgr0JlaVpf0//LY3LRw3lo9c78ZNf7QGckvflo4ZwzYTjePzP6dzyry01gmmsiU9QjhlcwtvPd+PaHw/h0IE4LpmeA8AzD2Twi1OGs/jNzpw/ZTcAA4eV4PUIl40eztTTh/GzX+/iqIxDzXkLjRfDJcWwB0URaQPMA25Q1f21bJ8mIstFZHk5peHOThXxCcqfntzKR6915POFHehxdClH9Spj1gfreebLtXTtUc6/39tAx67lVY7bkZnCoQNx9B4Ypb/QARh0YjGjzyrkmaWrufXfWxh2ShE3P7Klyj6L3+jIqecUAFBeFkdRgVPqyVzVmuxtyaT1jd3vB2BvThJ7dyWx/hunRPzpwk4cM7ikyj6L3+rMqRP2ATBuYh4rlrTHUxFHYV4ia5a3of/xJTXOGxVCNMVpJAprUBSRRJyA+LyqvlbbPqo6W1VHqurIRJqywVn5/YM72LExhddmO21CW79vxSXHD2bqSYOYetIg9uQkcs3ZA9i3J5HuGaXExTv/yt3SykjvV8rurKQmzG/T+s9f07j8xKFMHTOEe6/pw7eft+Vv1/WhZ5/DgW70WYXscHub23cqJy7O+X6O6lVKWp9Sdm2Ptg6E4Ozbm8SenCTS+x4EYMTJhWzPbEXP3n7f0Zn72LHZ+Y5ydyYxbMx+QElu5eHYEcVkbarZTBMNxOsNaIlG4ex9FuApYJ2q/j1c12mswaNKOPPifWxem8Kji9YD8J97e/DVR+1q3X/IqBIuuXYLFRWC1yv887Z09udHYXvQEbry1mzS+x7Cq5CblVTZ8zx0dDFTbszB4xE8HnjklozKkmMse3TG0dz80CYSk5Sc7cn8/Q99ueGvW0jvewhV2L0zmX/e3huA+c9258b7N/P4e6tBlEWvdmXL9zWbJyKeEtMPb4uGqd4vIqcCnwKrOPwV3qaqC+o6pp100pOk1gF3DUBclPZUNiFJjP1AfCS+KF3Ifm/eEfUQtk/tqaMHXRXQvu8vv3NFfRNXRaJw9j5/Ru1TDxpjol2UdqIEwv6sGmOCF8NB0aY4NcYEx9emGMhSDxHJEJHFIrJORNaIyPVu+p0islNEvnGXc/2OuVVEMkVkvYic7Zd+goiscrc94vZpNIqVFI0xQQtRz7LvrbeV7vzPK0RkkbvtIVV9oMo1nTfiJgGDgZ7AByIywJ3mdBYwDfgCWABMoJHTnFpJ0RgTpAAf3G6giq2qOaq60l0vAnxvvdVlIvCSqpaq6hYgExglIj2Adqq6VJ2e47nABY29OwuKxpjgKCF/o6WWt96uFZHvRGSOiHR009KAHX6HZblpae569fRGsaBojAle4G2KXXxvrLnLtOqnquWtt1lAP2A4zvgJD/p2rSUnWk96o1ibojEmaEEMMru3vucUa3vrTVV3+21/Anjb/ZgFZPgdng5ku+nptaQ3ipUUjTHBC0H1ua633tw2Qp8LgdXu+lvAJBFJFpE+QH9gmTsiV5GIjHbPOQV4s7G3ZiVFY0xwVMETkt7nU4BfAKtE5Bs37TZgsogMx6kCbwWuci6ra0TkFZzhByuAa9yeZ4DpwNNAK5xe50b1PIMFRWNMY4Tg4e163nqr81VgVZ0JzKwlfTkw5IgzhQVFY0xjxPAbLRYUjTHBUSCG52ixoGiMCZKCxu7YYRYUjTHBUULV0RKRLCgaY4JnbYrGGOPHgqIxxvhE70x9gbCgaIwJjgJROilVICwoGmOCZyVFY4zxCdlrfhHJgqIxJjgKas8pGmOMH3ujxRhj/FibojHGuFSt99kYY6qwkqIxxvgo6vE0vFuUsqBojAmODR1mjDHV2CM5xhjjUECtpGiMMS61QWaNMaaKWO5oEY2grnUR2QNsa+58+OkC7G3uTEQw+34aFmnf0dGq2vVITiAi7+LcVyD2quqEI7leU4uooBhpRGS5qo5s7nxEKvt+GmbfUfSJa+4MGGNMJLGgaIwxfiwo1m92c2cgwtn30zD7jqKMtSkaY4wfKykaY4wfC4rGGOPHgmItRGSCiKwXkUwRuaW58xNpRGSOiOSKyOrmzkskEpEMEVksIutEZI2IXN/ceTKBszbFakQkHtgA/AjIAr4CJqvq2mbNWAQRkdOBYmCuqg5p7vxEGhHpAfRQ1ZUi0hZYAVxgv0PRwUqKNY0CMlV1s6qWAS8BE5s5TxFFVZcA+c2dj0ilqjmqutJdLwLWAWnNmysTKAuKNaUBO/w+Z2G/0KaRRKQ3MAL4spmzYgJkQbEmqSXN2hhM0ESkDTAPuEFV9zd3fkxgLCjWlAVk+H1OB7KbKS8mSolIIk5AfF5VX2vu/JjAWVCs6Sugv4j0EZEkYBLwVjPnyUQRERHgKWCdqv69ufNjgmNBsRpVrQCuBd7DaSB/RVXXNG+uIouIvAgsBQaKSJaIXNnceYowpwC/AH4oIt+4y7nNnSkTGHskxxhj/FhJ0Rhj/FhQNMYYPxYUjTHGjwVFY4zxY0HRGGP8WFCMIiLicR/vWC0i/xWR1kdwrqdF5CJ3/UkRGVTPvmNF5ORGXGOriNSY9a2u9Gr7FAd5rTtF5KZg82hMdRYUo8tBVR3ujkxTBlztv9Ed4SdoqvrrBkZwGQsEHRSNiUYWFKPXp8AxbilusYi8AKwSkXgRuV9EvhKR70TkKnDeshCRf4nIWhF5B+jmO5GIfCwiI931CSKyUkS+FZEP3QENrgZ+55ZSTxORriIyz73GVyJyintsZxF5X0S+FpHHqf098ipE5A0RWeGOOzit2rYH3bx8KCJd3bR+IvKue8ynInJsSL5NY1wJzZ0BEzwRSQDOAd51k0YBQ1R1ixtYClX1RBFJBj4XkfdxRmoZCAwFugNrgTnVztsVeAI43T1XJ1XNF5HHgGJVfcDd7wXgIVX9TER64bz9cxwwA/hMVe8SkfOAKkGuDle412gFfCUi81Q1D0gFVqrqjSJyh3vua3EmgrpaVTeKyEnAo8APG/E1GlMrC4rRpZWIfOOuf4rzfu3JwDJV3eKmnwUc72svBNoD/YHTgRdV1QNki8hHtZx/NLDEdy5VrWvMxDOBQc4rvgC0cwdTPR34qXvsOyKyL4B7uk5ELnTXM9y85gFe4GU3/TngNXfUmZOB//pdOzmAaxgTMAuK0eWgqg73T3CDQ4l/EvBbVX2v2n7n0vAQaBLAPuA0u4xR1YO15CXg90ZFZCxOgB2jqgdE5GMgpY7d1b1uQfXvwJhQsjbF2PMeMN0dugoRGSAiqcASYJLb5tgDGFfLsUuBM0Skj3tsJze9CGjrt9/7OFVZ3P2Gu6tLgMvctHOAjg3ktT2wzw2Ix+KUVH3iAF9p91Kcavl+YIuIXOxeQ0RkWAPXMCYoFhRjz5M47YUrxZlY6nGcGsHrwEZgFTAL+KT6gaq6B6cd8DUR+ZbD1df5wIW+jhbgOmCk25GzlsO94H8GTheRlTjV+O0N5PVdIEFEvgPuBr7w21YCDBaRFThthne56ZcBV7r5W4NNFWFCzEbJMcYYP1ZSNMYYPxYUjTHGjwVFY4zxY0HRGGP8WFA0xhg/FhSNMcaPBUVjjPHz/wH5UnUy2GVW5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# make predictions using your model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# convert predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# create the confusion matrix\n",
    "conf_mat = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)\n",
    "\n",
    "# plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
